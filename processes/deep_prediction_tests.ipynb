{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de la decision forte\n",
    "##### Ou comment prendre une decision quand ça ne va pas tout droit\n",
    "\n",
    "Après avoir entrainé le modèle, nous testons dans ce notebook ses prédictions avec une vidéo.\n",
    "\n",
    "Cf partie 6 section 4 du rapport\n",
    "\n",
    "### Segmentation du code\n",
    "\n",
    " 1. Définition des constantes\n",
    " 2. Création de la chaine de traitement\n",
    " 4. Création du pipeline passant de la frame à la prédiction \n",
    " 8. Chargement du modèle\n",
    " 9. Application à une vidéo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = \"../data/videos/\"\n",
    "OUTPUT_PATH = \"../data/outputs/\"\n",
    "WEIGHTS_PATH = \"../data/weights/weights_tf_last.h5\"\n",
    "\n",
    "WIDTH, HEIGHT = 456, 228\n",
    "\n",
    "SESSION = tf.Session()\n",
    "keras.backend.set_session(SESSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de la chaine de pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize():\n",
    "    \"\"\"\n",
    "    Divide by 2 the image dimensions\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Apply the transformation\n",
    "\n",
    "        @param image: a OpenCV image\n",
    "        @return: the resized image\n",
    "        \"\"\"\n",
    "        image = cv2.resize(sample, (0,0), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "class Crop:\n",
    "    \"\"\"\n",
    "    Remove pixels on the top and the right\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Apply the transformation\n",
    "\n",
    "        @param image: a OpenCV image\n",
    "        @return: the cropped image\n",
    "        \"\"\"\n",
    "        width = sample.shape[1]\n",
    "        return sample[45:, :width-5]\n",
    "\n",
    "    \n",
    "class Normalize():\n",
    "    \"\"\"\n",
    "    Normalized the image with mean of 0 and std of 1\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Apply the transformation\n",
    "        \n",
    "        @param image: a grayscale OpenCV image\n",
    "        @return: a Numpy array normalized image with dimension of (69, 223, 1)\n",
    "        \"\"\"\n",
    "        image = sample\n",
    "        norm_img = np.zeros(image.shape)\n",
    "        norm_img = cv2.normalize(image, norm_img, 0, 1, cv2.NORM_MINMAX)\n",
    "        norm_img = norm_img.reshape(69, 223, -1)\n",
    "        \n",
    "        return norm_img\n",
    "    \n",
    "\n",
    "class DataFormatting:\n",
    "    \"\"\"\n",
    "    Chnage data type of a Numpy array\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Apply the transformation\n",
    "\n",
    "        @param sample: a Numpy image\n",
    "        @return: the Numpy float32 image\n",
    "        \"\"\"\n",
    "        image = sample.astype(np.float32)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "class ToTensor:\n",
    "    \"\"\"\n",
    "    Add the batch dimension in axis 0\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Apply the transformation\n",
    "        \n",
    "        @param image: a Numpy array of dimension (69, 223, 1)\n",
    "        @return: a Numpy array of dimension (1, 69, 223, 1)\n",
    "        \"\"\"\n",
    "        image = sample.reshape(-1, 69, 223, 1)\n",
    "        image = image.astype(np.float32)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "class ProcessChain:\n",
    "    \"\"\"\n",
    "    Create the preprocess pipeline before going in the CNN.\n",
    "    Each element must be callable. \n",
    "    Take care about the dimension between the return and the argument for the next class.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialization of the preprocess pipeline, \"line\"\n",
    "        \"\"\"\n",
    "        self.line = [\n",
    "            Resize(),\n",
    "            Crop(),\n",
    "            Normalize(),\n",
    "            ToTensor()\n",
    "        ]\n",
    "\n",
    "    def transform(self, image):\n",
    "        \"\"\"\n",
    "        Iterate through \"line\" and return the last item\n",
    "        \n",
    "        @param image: a OpenCV image of dimension (456, 228, 3)\n",
    "        @return: a Numpy array of dimension (1, 69, 223, 1)\n",
    "        \"\"\"\n",
    "        item = image\n",
    "        for process in self.line:\n",
    "            item = process(item)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [\n",
    "    Resize(),\n",
    "    Crop(),\n",
    "    Normalize(),\n",
    "    DataFormatting(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du pipeline passant de la frame à la prédiction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image2Prediction:\n",
    "    \"\"\"\n",
    "    The pipeline predicting speed and direction\n",
    "    from a frame of a dataset video \n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        \"\"\"\n",
    "        Initialization of the pipeline\n",
    "        \n",
    "        @param model: the pretrained keras model\n",
    "        \"\"\"\n",
    "        self.process = ProcessChain()\n",
    "        self.model = model\n",
    "        \n",
    "    def analyze(self, frame):\n",
    "        \"\"\"\n",
    "        Predict the speed and the direction\n",
    "        \n",
    "        @param frame: a Numpy image\n",
    "        @return: the raw direction and speed prediction\n",
    "        \"\"\"\n",
    "        with SESSION.as_default():\n",
    "            image = self.process.transform(frame)\n",
    "            p_dir, p_speed = self.model.predict(image)[0]\n",
    "            \n",
    "            return p_dir, p_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(3, (3, 3), padding=\"valid\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        layers.Conv2D(3, (3, 3), padding=\"valid\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        layers.Conv2D(3, (3, 3), padding=\"valid\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        \n",
    "        layers.Dense(50, activation=\"relu\"),\n",
    "        layers.Dense(8, activation=\"relu\"),\n",
    "        layers.Dense(2, activation=None),\n",
    "    ])\n",
    "\n",
    "    model.build((1, 69, 223, 1))\n",
    "    model.load_weights(WEIGHTS_PATH)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application à une vidéo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20a4a7d49544f67a4070cec8bf3e29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Frames:   0%|          | 0/3603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/work/.miniconda3/envs/titaniumcar/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FOLDER_PATH + 'move_by_hand1.mp4')\n",
    "out = cv2.VideoWriter(\n",
    "    OUTPUT_PATH + 'deep_prediciton.mp4',\n",
    "    cv2.VideoWriter_fourcc('M','J','P','G'),\n",
    "    20, (WIDTH, HEIGHT)\n",
    ")\n",
    "\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "    \n",
    "# Progress bar\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total=length, desc=\"Frames\")\n",
    "\n",
    "model = Image2Prediction(build_model())\n",
    "\n",
    "current_dir = 0\n",
    "current_speed = 0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        dir_prediction, speed_prediction = model.analyze(frame)\n",
    "        \n",
    "        val_dir = dir_prediction*WIDTH/2\n",
    "        val_dir += WIDTH/2\n",
    "        val_dir = int(val_dir)\n",
    "        val_speed = speed_prediction*HEIGHT/2\n",
    "        val_speed += HEIGHT/2\n",
    "        val_speed = int(val_speed)\n",
    "\n",
    "        # show prediction in the frame\n",
    "        cv2.circle(frame, (val_dir, val_speed), 10, (255, 0, 0), -1)\n",
    "        out.write(frame)\n",
    "        pbar.update()\n",
    "    \n",
    "    # break at the end of the process which is predicting the speed and the direction from a dataset video frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "pbar.close()\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
