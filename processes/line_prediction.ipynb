{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm, tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- __/!\\ /!\\ /!\\__ Ne possède ni l'intertie de la direction ni la jauge de vitesse __/!\\ /!\\ /!\\__ -->\n",
    "\n",
    "Le fichier *line_prediction.py* dans le dossier titaniumcar reprend le code créé ici.\n",
    "\n",
    "# Prise de decision faible\n",
    "\n",
    "Après un pre-process commun (gray scale + blur + edge detection + region of interest), la fonction \"HoughLinesP\" est appliquée.\n",
    "\n",
    "Avec ces lignes, le programme récupère le point de croisement entre la droite et le haut de l'image. Une moyenne pondérée par la longueur de la ligne est faite. Ce point résultant détermine la direction et la vitesse.\n",
    "\n",
    "Cf partie 5 du rapport\n",
    "\n",
    "### Segmentation du code\n",
    "\n",
    " 1. Définition des constantes\n",
    " 2. Création de la chaine de traitement\n",
    "     * Pre-process\n",
    "     * Hough lines\n",
    " 3. Modèle pour la prise de décision\n",
    " 5. Application à une vidéo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 456, 228\n",
    "\n",
    "FOLDER_PATH = \"../data/videos/\"\n",
    "OUTPUT_PATH = \"../data/outputs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de la chaine de traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessChain:\n",
    "    def canny_trsf(self, image):\n",
    "        \"\"\"\n",
    "        Apply a Gaussian blur to smooth the image\n",
    "        Edge detection from an RGB image\n",
    "\n",
    "        @param image: a RGB OpenCV image\n",
    "        @return: the edges of image\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        canny = cv2.Canny(blur, 20, 100)\n",
    "        return canny\n",
    "\n",
    "    def region_of_interest(self, image):\n",
    "        \"\"\"\n",
    "        Set to (0, 0, 0) each pixel outside the roi\n",
    "\n",
    "        @param image: a grayscale OpenCV image\n",
    "        @return: the image with only roi\n",
    "        \"\"\"\n",
    "        height = image.shape[0]\n",
    "        # coordinates of the roi\n",
    "        poly = np.array([\n",
    "            (0, 131),\n",
    "            (0, height),\n",
    "            (454, height),\n",
    "            (454, 131),\n",
    "            (300, 94),\n",
    "            (150, 94)\n",
    "        ])\n",
    "        mask = np.zeros_like(image)\n",
    "        cv2.fillPoly(mask, (poly,), 255)\n",
    "        masked_image = cv2.bitwise_and(image, mask)\n",
    "        return masked_image\n",
    "        \n",
    "    def detect_lines(self, image):\n",
    "        \"\"\"\n",
    "        Find the segments in the picture\n",
    "        \n",
    "        @param image: a grayscale OpenCV image with only bound\n",
    "        @return: lines in a Numpy array  \n",
    "        \"\"\"\n",
    "        lines = cv2.HoughLinesP(image, 3, np.pi/180, 100, np.array([]), minLineLength=37, maxLineGap=37)\n",
    "        return lines\n",
    "        \n",
    "    def line_process(self, lines):\n",
    "        \"\"\"\n",
    "        Find the point of convergence of lines\n",
    "        The lines are filtered to keep only relevant lines\n",
    "        \n",
    "        @param lines: list or Numpy array with coordinates of lines\n",
    "        @return: None if all lines are not relevant else float\n",
    "        \"\"\"\n",
    "        if lines is None:\n",
    "            return None\n",
    "\n",
    "        lenghts = np.array([])\n",
    "        origins = np.array([])\n",
    "        nb_ignored = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            # get lenght of the line\n",
    "            # and coordinate of intersection of line and abscissa\n",
    "            x1, y1, x2, y2 = line.reshape(4)\n",
    "            if y1 == y2:\n",
    "                continue\n",
    "            \n",
    "            a = (x1-x2)/(y1-y2)\n",
    "            b = x1 - a*y1\n",
    "            \n",
    "            lenght = np.sqrt(np.square(x1-x2)+np.square(y1-y2))\n",
    "            # if intersection point if too away, remove it\n",
    "            if 0-300 < b < 456+300:\n",
    "                origins = np.append(origins, b)\n",
    "                lenghts = np.append(lenghts, lenght)\n",
    "            # when length is too small, the uncertainty of the direction is too large \n",
    "            # so, just increment counter\n",
    "            elif lenght > 75:\n",
    "                nb_ignored += 1\n",
    "        \n",
    "        if len(origins) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            pt_mean = np.average(origins, weights=lenghts)  \n",
    "            \n",
    "            # If the convergence point is on the sides,\n",
    "            # the ignored lines could be revelant  \n",
    "            if pt_mean > 0.5:\n",
    "                pt_mean *= 1 + nb_ignored / 3\n",
    "            return  pt_mean\n",
    "\n",
    "    def transform(self, image):\n",
    "        \"\"\"\n",
    "        Apply all transformations\n",
    "        \n",
    "        @param image: a OpenCV image of dimension (456, 228, 3)\n",
    "        @return: mean direction of the edges of the circuit (float)\n",
    "        \"\"\"\n",
    "        image = self.canny_trsf(image)\n",
    "        image = self.region_of_interest(image)\n",
    "        lines = self.detect_lines(image)\n",
    "        \n",
    "        return self.line_process(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model pour la prise de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image2Prediction():\n",
    "    \"\"\"\n",
    "    Wrap the whole process from frame to apply predicted speed and direction\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialization of the attributes\n",
    "        and create preprocess pipeline with ProcessChain class\n",
    "        \"\"\"\n",
    "        self.process = ProcessChain()\n",
    "        self.queue = deque([0 for _ in range(12)])\n",
    "    \n",
    "    def analyze(self, frame):\n",
    "        \"\"\"\n",
    "        For each frame, this method is called\n",
    "        The steps are :\n",
    "         * get the mean direction of the edges of the circuit  \n",
    "         * predict the direction and the speed\n",
    "        \n",
    "        @param frame: a Numpy array usable like a OpenCV image\n",
    "        \n",
    "        @return dir_prediction: the predicted direction (between -1 and 1)\n",
    "        @return speed_prediction: the predicted speed (between -1 and 1)\n",
    "        \"\"\"\n",
    "        pt = self.process.transform(frame)\n",
    "        if pt is not None:\n",
    "            dir_prediction, speed_prediction = self.predict(pt)\n",
    "        else:\n",
    "            dir_prediction, speed_prediction = None, 0.33\n",
    "        return dir_prediction, speed_prediction\n",
    "\n",
    "    def predict(self, x, shape=(HEIGHT, WIDTH)):\n",
    "        \"\"\"\n",
    "        Predict the speed and the direction with the target point and the previous ones\n",
    "        \n",
    "        If the direction is straightforward for a while,\n",
    "        the speed can be increase!\n",
    "        \n",
    "        @param x: the taget point of the car\n",
    "        @param shape: video frame dimensions\n",
    "        \n",
    "        @return p_dir: the desired direction (between -1 and 1)\n",
    "        @return p_speed: the desired speed (between -1 and 1)\n",
    "        \"\"\"\n",
    "        x = (x-shape[1]/2)/shape[1]\n",
    "        p_dir = 2.5 * np.arctan(x)\n",
    "        \n",
    "        self.queue.appendleft(p_dir)\n",
    "        self.queue.pop()\n",
    "        \n",
    "        if p_dir > 1:\n",
    "            p_dir = 1\n",
    "        elif p_dir < -1:\n",
    "            p_dir = -1\n",
    "        \n",
    "        dA = np.mean([self.queue[i] for i in range(4)])\n",
    "        dB = np.mean([self.queue[-i] for i in range(4)])\n",
    "        p_speed = 1 - (np.abs(dA)*0.9)\n",
    "                \n",
    "        return p_dir, p_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application à une vidéo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd138d58236497385791690811854bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Frames:   0%|          | 0/3603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(FOLDER_PATH + 'move_by_hand1.mp4')\n",
    "out = cv2.VideoWriter(\n",
    "    OUTPUT_PATH + 'hough_lines_prediction.mp4',\n",
    "    cv2.VideoWriter_fourcc('M','J','P','G'),\n",
    "    20, (WIDTH, HEIGHT)\n",
    ")\n",
    "\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "    \n",
    "# Progress bar\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total=length, desc=\"Frames\")\n",
    "\n",
    "model = Image2Prediction()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        dir_prediction, speed_prediction = model.analyze(frame)\n",
    "        \n",
    "        if dir_prediction:\n",
    "            # translate the prediction to coordinates\n",
    "            val_dir = dir_prediction*WIDTH/2\n",
    "            val_dir += WIDTH/2\n",
    "            val_dir = int(val_dir)\n",
    "            val_speed = speed_prediction*HEIGHT/2\n",
    "            val_speed += HEIGHT/2\n",
    "            val_speed = HEIGHT - val_speed\n",
    "            val_speed = int(val_speed)\n",
    "            \n",
    "        # show prediction in the frame\n",
    "            cv2.circle(frame, (val_dir, val_speed), 10, (255, 0, 0), -1)\n",
    "        # else draw red circle in the frame center\n",
    "        else:\n",
    "            cv2.circle(frame, (456//2, 228//2), 10, (0, 0, 255), -1)\n",
    "        out.write(frame)\n",
    "        pbar.update()\n",
    "        \n",
    "    # break at the end of the video\n",
    "    else: \n",
    "        break\n",
    "\n",
    "pbar.close()\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
